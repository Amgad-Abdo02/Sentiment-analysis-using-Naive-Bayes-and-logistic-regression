{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Importing used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\bsbs\n",
      "[nltk_data]     meow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\bsbs\n",
      "[nltk_data]     meow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i seriously hate one subject to death but now ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im so full of life i feel appalled</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i sit here to write i start to dig out my feel...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive been really angry with r and i feel like a...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i feel suspicious if there is no one outside l...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Emotion\n",
       "0  i seriously hate one subject to death but now ...    fear\n",
       "1                 im so full of life i feel appalled   anger\n",
       "2  i sit here to write i start to dig out my feel...    fear\n",
       "3  ive been really angry with r and i feel like a...     joy\n",
       "4  i feel suspicious if there is no one outside l...    fear"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "data = pd.read_csv(\"Emotion_classify_data.csv\")\n",
    "\n",
    "#drop missing values\n",
    "data = data.dropna()\n",
    "\n",
    "#Show the first few rows\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens  \\\n",
      "0  [i, seriously, hate, one, subject, to, death, ...   \n",
      "1        [im, so, full, of, life, i, feel, appalled]   \n",
      "2  [i, sit, here, to, write, i, start, to, dig, o...   \n",
      "3  [ive, been, really, angry, with, r, and, i, fe...   \n",
      "4  [i, feel, suspicious, if, there, is, no, one, ...   \n",
      "\n",
      "                                             stemmed  \\\n",
      "0  [i, serious, hate, one, subject, to, death, bu...   \n",
      "1           [im, so, full, of, life, i, feel, appal]   \n",
      "2  [i, sit, here, to, write, i, start, to, dig, o...   \n",
      "3  [ive, been, realli, angri, with, r, and, i, fe...   \n",
      "4  [i, feel, suspici, if, there, is, no, one, out...   \n",
      "\n",
      "                                          lemmatized  \n",
      "0  [i, seriously, hate, one, subject, to, death, ...  \n",
      "1        [im, so, full, of, life, i, feel, appalled]  \n",
      "2  [i, sit, here, to, write, i, start, to, dig, o...  \n",
      "3  [ive, been, really, angry, with, r, and, i, fe...  \n",
      "4  [i, feel, suspicious, if, there, is, no, one, ...  \n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "data['tokens'] = data['Comment'].apply(word_tokenize)\n",
    "\n",
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "data['stemmed'] = data['tokens'].apply(lambda x: [stemmer.stem(token) for token in x])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['lemmatized'] = data['tokens'].apply(lambda x: [lemmatizer.lemmatize(token) for token in x])\n",
    "\n",
    "# Display the first few rows with tokenization, stemming, and lemmatization\n",
    "print(data[['tokens', 'stemmed', 'lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the stemmed words into a bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['stemmed'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "# Split the data into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, data['Emotion'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.8838383838383839\n"
     ]
    }
   ],
   "source": [
    "NB = MultinomialNB()\n",
    "\n",
    "#Training model\n",
    "NB.fit(X_train, y_train)\n",
    "\n",
    "#Predicting Model\n",
    "prediction = NB.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9208754208754208\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=500)\n",
    "\n",
    "#training model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#prediction model\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Text:  The monster is in the closet \n",
      "Text 1 Prediction - Logistic Regression: joy \n",
      "Text 1 Prediction - Naive Bayes: fear \n",
      "\n",
      "input Text:  the scary movie was so fun \n",
      "Text 2 Prediction - Logistic Regression: joy \n",
      "Text 2 Prediction - Naive Bayes: fear \n",
      "\n",
      "input Text:  i adore this pizza,its my favourite \n",
      "Text 3 Prediction - Logistic Regression: anger \n",
      "Text 3 Prediction - Naive Bayes: anger \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict_emotion(text):\n",
    "    # Preprocess the input text\n",
    "    tokens = word_tokenize(text)\n",
    "    stemed = [stemmer.stem(token) for token in tokens]\n",
    "    input_vector = vectorizer.transform([' '.join(stemed)])\n",
    "\n",
    "    # Predict using both models\n",
    "    lr = model.predict(input_vector)[0]\n",
    "    nb = NB.predict(input_vector)[0]\n",
    "\n",
    "    return lr, nb\n",
    "\n",
    "# Test the function with sample texts\n",
    "text1 = \"The monster is in the closet\"\n",
    "text2 = \"the scary movie was so fun\"\n",
    "text3 = \"i adore this pizza,its my favourite\"\n",
    "\n",
    "result1 = predict_emotion(text1)\n",
    "result2 = predict_emotion(text2)\n",
    "result3 = predict_emotion(text3)\n",
    "\n",
    "print(\"input Text: \",text1,\"\\nText 1 Prediction - Logistic Regression:\", result1[0], \"\\nText 1 Prediction - Naive Bayes:\", result1[1],\"\\n\")\n",
    "print(\"input Text: \",text2,\"\\nText 2 Prediction - Logistic Regression:\", result2[0], \"\\nText 2 Prediction - Naive Bayes:\", result2[1],\"\\n\")\n",
    "print(\"input Text: \",text3,\"\\nText 3 Prediction - Logistic Regression:\", result3[0], \"\\nText 3 Prediction - Naive Bayes:\", result3[1],\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
